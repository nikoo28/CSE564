\documentclass[letterpaper,12pt]{article}
\usepackage[margin=0.75in]{geometry}
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{setspace}
\usepackage{titlesec}

\title{Natural Human-Robot Interaction Using Social Cues\\A critical review}
\vspace{-0.35cm}
\author{\textbf{Professor:} \\  Dr. Ashraf Gaffar \\
\vspace{-0.35cm}
\\
  Nikhil Lohia (1211168085)\\
  \vspace{-0.25cm}
  \small{Computer Science and Engineering Program} \\
  \vspace{-0.25cm}
  \footnotesize{CSE 564 : Software Design}\\
  \vspace{-0.25cm}
  \footnotesize{Arizona State University}\\
  \vspace{-0.25cm}
  \footnotesize{Email: nlohia1@asu.edu}}

\date{October 11, 2016}
\providecommand{\keywords}[1]{\textbf{\textit{Keywords---}} #1}
\begin{document}

\thispagestyle{empty}
\maketitle
\vspace{-0.95cm}
\begin{abstract}
\noindent The paper intends to explore a new side to the human and robot interaction in the terms of `Team Work'. Humans are good at collaborating with each other and working in teams but what if this challenge is posed when working in teams with robots. A teamwork is always targeted towards a certain shared goal while working independently or working in joint-actions. This involves taking up of modules, sharing knowledge, understanding problems and working out an effective solution. 
\par
\indent We are introduced to the term of `affordance' which is described as the ``acquired relation between the behavior of an agent and an entity in the environment such that the application of the behavior on the entity generates a certain effect''. We can understand affordance in the terms as how feasible a task is for a certain individual. Some tasks might be easy for a robot, while it may be difficult for a human. If a human performs repetitive tasks, he/she may end up making a fault in one of them. Robots on the other hand can be specifically very good at handling repetitive tasks. Other kind of affordance tasks can be moving around objects.
\par
\indent Sometimes, this affordance must be perceived before assigning a task. We must have a knowledge of the capabilities before we assign a task to some individual. Same applies for a robot as well. For example, if we rely upon a robot to perform $n$ tasks in a limited number of time, we must make sure that the robot is fast enough to complete it. The research in the paper attempts to explore how a human behavior changes based upon the affordance capabilities of the robot.
\end{abstract}

\section{Critical Review}
The paper ``Natural Human-Robot Interaction Using Social Cues'' attempts to introduce the readers to a more practical and real life example of using robots. Robots are generally used today when programmed to do a certain task. In this paper the author tries to intrigue the reader with possibilities of collaborating with a robot. The author tries to discuss about team work. A team work involves some joint effort and we must be able to know if the other member would be able to complete the assigned task.
\par
\indent The paper tries to highlight the fact that a better collaborative measure can be observed if the robot is able to give some social cues. Social cues in this case indicate the `affordance'. The robot indicates whether it would be able to complete the given task or not.

\subsection{Experiment}
The paper describes an experiment of arranging 5 $Duplo$ blocks in a particular sequence. A human and a robot are placed on opposite ends of a table. The table has some specific arrangements of $Duplo$ blocks. Some blocks are in reach of the user and some blocks are in reach of the robot. The user does not know which blocks are not in reach of the robot. The users are of varied domains both males and females. The shared goal of robot and human is to arrange the blocks in a certain sequence. The following scenarios are observed.

\small
\subsubsection{Test Cases}
\begin{itemize}
\item \textbf{Scenario A:} Half the blocks are located on the side of human and half the blocks are located on the side of robot.
\item \textbf{Scenario B:} Two blocks are located within reach of the human, but out-of-reach of the robot, and two within reach of the robot.
\item \textbf{Scenario C:} Two blocks are located within reach of the human, but out-of-reach of the robot, one within reach of the robot. The robot is capable of giving a social cue to the human to determine which block it cannot reach.
\item \textbf{Scenario D:} Blocks are arranged in a straight line; the two hands of the robot are fully occupied each holding a block.
\item \textbf{Scenario E:} All the blocks are placed on the side of the participant. The robot is again capable of giving a social cue which means `unable to reach'. The robots points at the blocks which it is unable to reach.
\end{itemize}

\subsubsection{Results}
\begin{itemize}
\item \textbf{Scenario A:} This was the fastest as both the human and the robot were able to achieve their assigned tasks and the affordance was same for both of them. Both of them were equally able to complete the task individually.
\item \textbf{Scenario B:} This setup took the longest amount of time as the user was unable to determine if the robot would be able to complete the assigned task or not. The user could not perceive that the robot was unable to reach to the parts. This took some time in understanding and the maximum variances were observed.
\item \textbf{Scenario C, D, E:} All the setups were pretty fast and took almost equal amount of time. The user understood what the robot was capable of.
\end{itemize}

\normalsize

\subsection{Results and Analysis}
It can be seen from the above results that the best team work is possible when all the team members are capable of doing their assigned task with equal competence (Scenario A). But such kind of a scenario is not possible practically.
\par
\indent As per the experiment, when the robot is capable of giving social cues and interacting with the user, better results are observed. In Scenario C the robot is capable of giving a gesture that it is unable to reach a block. This enables the human to perceive that he needs to take some action to achieve the task. In Scenario D, the robot's hand is full with all the blocks, that means it can reach all the blocks and perform the task. In Scenario E, the robot physically points at the blocks it cannot reach, the user then assists the robot to complete the desired sequence of the $Duplo$ blocks. In all the 3 scenarios we have some means of interacting with the robot which achieves the shared goal.
\par
\indent Scenario B was the worst scenario and it showed a situation where team members were unaware of the competencies  of other members. Both the human and robot relied on the other person to complete the task.

\section{Conclusion}
By performing this experiment of \textit{`pick and place'} we were able to understand that when the robot did not offer any cue, the joint action took a lot of time. Analyzing the graphs, it can be observed that although the users took some time to understand what was happening, when the robot was holding all the blocks; still they were able to get a cue from the robot about its capability. Obviously, the best results were seen when the robot gave a specific cue.
\par The paper explores that sometimes only affordance cannot determine if a task can be completed or not. We must be able to give a cue also which explores if the task is possible. The paper also establishes that the human and robot are capable of working in a collaborative environment. The robot is not just limited to a passive environment where it performs a certain programmed task. With the help of cues, it can communicate with the human. We intend to make this process as efficient as possible.
\par
The paper however does not explore the results when more than one human and robots are engaged in the same scenario. We do not know if the total time taken to complete the process will be reduced or increased in these cases. When two humans work on the same project, generally the time is reduced, but can we say the same when two robots are working on the same team/group. Such observations can be a further area of research to establish some facts.

\begin{thebibliography}{9}
\footnotesize
\setlength{\itemsep}{0pt}
\bibitem{GMS94}
Hugo Romat, Xun-Wang, Benjamin Johnston, Henry Bard, Mary-Anne Williams, ``Natural Human-Robot Interaction Using Social Cues'', \emph{The Eleventh ACM/IEEE International Conference on Human Robot Interaction}, 2016, pages 503-504
\end{thebibliography}

\end{document}
